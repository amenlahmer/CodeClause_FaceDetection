{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications import VGG16\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-18T09:44:51.806631Z","iopub.execute_input":"2023-07-18T09:44:51.807016Z","iopub.status.idle":"2023-07-18T09:44:53.776685Z","shell.execute_reply.started":"2023-07-18T09:44:51.806984Z","shell.execute_reply":"2023-07-18T09:44:53.775822Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\npip install ultralytics\n","metadata":{"execution":{"iopub.status.busy":"2023-07-18T09:44:53.778689Z","iopub.execute_input":"2023-07-18T09:44:53.779693Z","iopub.status.idle":"2023-07-18T09:45:04.940583Z","shell.execute_reply.started":"2023-07-18T09:44:53.779657Z","shell.execute_reply":"2023-07-18T09:45:04.939427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**IMPORTS**","metadata":{}},{"cell_type":"code","source":"# System libraries\nimport os\nimport random\nimport yaml\nfrom PIL import Image\nfrom tqdm import tqdm\n\n\n\n\n# Data analytics and visualisations\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle\n\n# PyTorch\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom torchvision import transforms as T\nfrom torchinfo import summary\n\n#CV2\nimport os\nimport numpy as np\nimport cv2\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","metadata":{"execution":{"iopub.status.busy":"2023-07-18T09:45:04.942339Z","iopub.execute_input":"2023-07-18T09:45:04.942647Z","iopub.status.idle":"2023-07-18T09:45:04.950930Z","shell.execute_reply.started":"2023-07-18T09:45:04.942618Z","shell.execute_reply":"2023-07-18T09:45:04.949995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data exploration","metadata":{}},{"cell_type":"code","source":"root = '/kaggle/input/wider-face-a-face-detection-benchmark/'\ntrain_img_folder = f\"{root}wider_train/WIDER_train/images/\"\nval_img_folder = f\"{root}wider_val/WIDER_val/images/\"\nannotations_folder = f\"{root}wider_face_split/wider_face_split/\"","metadata":{"execution":{"iopub.status.busy":"2023-07-18T09:45:04.953886Z","iopub.execute_input":"2023-07-18T09:45:04.954281Z","iopub.status.idle":"2023-07-18T09:45:04.963431Z","shell.execute_reply.started":"2023-07-18T09:45:04.954249Z","shell.execute_reply":"2023-07-18T09:45:04.962556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\n\n\n# Get a list of all subfolders within the main folder\nsubfolders = [f for f in os.listdir(train_img_folder) if os.path.isdir(os.path.join(train_img_folder, f))]\n\n# Print the names of the subfolders\nfor folder in subfolders:\n    print(folder)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-18T09:45:04.965300Z","iopub.execute_input":"2023-07-18T09:45:04.965775Z","iopub.status.idle":"2023-07-18T09:45:04.979547Z","shell.execute_reply.started":"2023-07-18T09:45:04.965740Z","shell.execute_reply":"2023-07-18T09:45:04.978447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport matplotlib.pyplot as plt\n\n# Path to the folder containing the images\nimage_folder = '/kaggle/input/wider-face-a-face-detection-benchmark/WIDER_train/WIDER_train/images/42--Car_Racing'\n\n# Get a list of image file names in the folder\nimage_files = [f for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))]\n\n# Display basic statistics of the dataset\nprint(\"Total number of images:\", len(image_files))\n\n# Plot a sample of images\nnum_samples = 5\n\nfig, axes = plt.subplots(1, num_samples, figsize=(15, 5))\n\nfor i in range(num_samples):\n    image_path = os.path.join(image_folder, image_files[i])\n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n    axes[i].imshow(img)\n    axes[i].axis('off')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-07-18T09:45:04.981498Z","iopub.execute_input":"2023-07-18T09:45:04.982178Z","iopub.status.idle":"2023-07-18T09:45:06.293986Z","shell.execute_reply.started":"2023-07-18T09:45:04.982125Z","shell.execute_reply":"2023-07-18T09:45:06.293119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = Image.open(f\"{train_img_folder}0--Parade/0_Parade_Parade_0_4.jpg\")\nplt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2023-07-18T09:45:06.295575Z","iopub.execute_input":"2023-07-18T09:45:06.296562Z","iopub.status.idle":"2023-07-18T09:45:06.805983Z","shell.execute_reply.started":"2023-07-18T09:45:06.296524Z","shell.execute_reply":"2023-07-18T09:45:06.805059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_size = (224, 224)","metadata":{"execution":{"iopub.status.busy":"2023-07-18T09:45:06.807464Z","iopub.execute_input":"2023-07-18T09:45:06.808457Z","iopub.status.idle":"2023-07-18T09:45:06.812723Z","shell.execute_reply.started":"2023-07-18T09:45:06.808423Z","shell.execute_reply":"2023-07-18T09:45:06.811841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = cv2.imread(\"/kaggle/input/wider-face-a-face-detection-benchmark/WIDER_val/WIDER_val/images/0--Parade/0_Parade_Parade_0_120.jpg\")\nimage = cv2.resize(image, input_size)\nimage = image / 255.0  # Normalize pixel values\nplt.imshow(image)","metadata":{"execution":{"iopub.status.busy":"2023-07-18T09:45:06.814110Z","iopub.execute_input":"2023-07-18T09:45:06.815210Z","iopub.status.idle":"2023-07-18T09:45:07.191951Z","shell.execute_reply.started":"2023-07-18T09:45:06.815169Z","shell.execute_reply":"2023-07-18T09:45:07.191064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\n\nimg = Image.open(f\"{train_img_folder}0--Parade/0_Parade_Parade_0_4.jpg\")\nimage_size = img.size\n\nprint(\"Image Size:\", image_size)","metadata":{"execution":{"iopub.status.busy":"2023-07-18T09:45:07.196831Z","iopub.execute_input":"2023-07-18T09:45:07.197517Z","iopub.status.idle":"2023-07-18T09:45:07.204640Z","shell.execute_reply.started":"2023-07-18T09:45:07.197482Z","shell.execute_reply":"2023-07-18T09:45:07.203601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir(annotations_folder)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-18T09:45:07.206561Z","iopub.execute_input":"2023-07-18T09:45:07.207305Z","iopub.status.idle":"2023-07-18T09:45:07.216807Z","shell.execute_reply.started":"2023-07-18T09:45:07.207249Z","shell.execute_reply":"2023-07-18T09:45:07.215653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_bbx_path = f\"{annotations_folder}wider_face_train_bbx_gt.txt\"\nval_bbx_path = f\"{annotations_folder}wider_face_val_bbx_gt.txt\"","metadata":{"execution":{"iopub.status.busy":"2023-07-18T09:45:07.218364Z","iopub.execute_input":"2023-07-18T09:45:07.219021Z","iopub.status.idle":"2023-07-18T09:45:07.225901Z","shell.execute_reply.started":"2023-07-18T09:45:07.218850Z","shell.execute_reply":"2023-07-18T09:45:07.224837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**bounding box**","metadata":{}},{"cell_type":"code","source":"def load_bbx(bbx_path):\n    with open(bbx_path, mode='r') as file:\n        lines = file.readlines()\n        \n    annotations = {}\n    i = 0\n    while i < len(lines):\n        file_name = lines[i].strip()\n        i += 1\n        num_boxes = int(lines[i].strip())\n        i += 1\n        boxes = []\n        for _ in range(num_boxes):\n            box_info = lines[i].strip().split()\n            box = {\n                'x': int(box_info[0]),\n                'y': int(box_info[1]),\n                'w': int(box_info[2]),\n                'h': int(box_info[3]),\n            }\n            boxes.append(box)\n            i += 1\n        annotations[file_name] = boxes\n\n    return annotations","metadata":{"execution":{"iopub.status.busy":"2023-07-18T09:45:07.227282Z","iopub.execute_input":"2023-07-18T09:45:07.228112Z","iopub.status.idle":"2023-07-18T09:45:07.238104Z","shell.execute_reply.started":"2023-07-18T09:45:07.228078Z","shell.execute_reply":"2023-07-18T09:45:07.237171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_annotations = load_bbx(train_bbx_path)\nval_annotations = load_bbx(val_bbx_path)\n\ntrain_keys = []\nval_keys = []\nfor key in train_annotations.keys():\n    train_keys.append(key)\nfor key in val_annotations.keys():\n    val_keys.append(key)","metadata":{"execution":{"iopub.status.busy":"2023-07-18T09:45:07.239688Z","iopub.execute_input":"2023-07-18T09:45:07.240032Z","iopub.status.idle":"2023-07-18T09:45:07.663876Z","shell.execute_reply.started":"2023-07-18T09:45:07.240000Z","shell.execute_reply":"2023-07-18T09:45:07.662894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**convert the dataset into a dataframe**","metadata":{}},{"cell_type":"code","source":"def annotation_to_df(annotation, img_shape):\n    cs, xs, ys, ws, hs = [], [], [], [], []\n    \n    h, w, _ = img_shape\n    for box in annotation:\n        cs.append(0)\n        xs.append((box[\"x\"] + box[\"w\"] / 2.0) / w)\n        ys.append((box[\"y\"] + box[\"h\"] / 2.0) / h)\n        ws.append(box[\"w\"] / w)\n        hs.append(box[\"h\"] / h)\n        \n    return pd.DataFrame({0:cs, 1:xs, 2:ys, 3:ws, 4:hs})","metadata":{"execution":{"iopub.status.busy":"2023-07-18T09:45:07.665321Z","iopub.execute_input":"2023-07-18T09:45:07.665728Z","iopub.status.idle":"2023-07-18T09:45:07.674557Z","shell.execute_reply.started":"2023-07-18T09:45:07.665692Z","shell.execute_reply":"2023-07-18T09:45:07.672652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**BoundingBoxesplotting**","metadata":{}},{"cell_type":"code","source":"def plot_boxes(img, df):\n    h, w, _ = img.shape\n    \n    fig, ax = plt.subplots()\n    for index, row in df.iterrows():\n        patch = Rectangle(\n            ((row[1] - row[3] / 2.0) * w, (row[2] - row[4] / 2.0) * h),\n            row[3] * w,\n            row[4] * h,\n            edgecolor = 'red',\n            fill=False,\n        )\n        ax.add_patch(patch)\n    \n    plt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2023-07-18T09:45:07.676315Z","iopub.execute_input":"2023-07-18T09:45:07.677113Z","iopub.status.idle":"2023-07-18T09:45:07.684778Z","shell.execute_reply.started":"2023-07-18T09:45:07.677081Z","shell.execute_reply":"2023-07-18T09:45:07.683767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sample plot\nkey = train_keys[random.randint(0, len(train_keys) - 1)]\nimg = np.array(Image.open(f\"{train_img_folder}{key}\"))\ndf = annotation_to_df(train_annotations[key], img.shape)\nplot_boxes(img, df)","metadata":{"execution":{"iopub.status.busy":"2023-07-18T09:45:07.686257Z","iopub.execute_input":"2023-07-18T09:45:07.686731Z","iopub.status.idle":"2023-07-18T09:45:08.317169Z","shell.execute_reply.started":"2023-07-18T09:45:07.686699Z","shell.execute_reply":"2023-07-18T09:45:08.316240Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# transforming the dataset ","metadata":{}},{"cell_type":"code","source":"def add_dataset(keys, annotations, img_folder, root, split):\n    if not os.path.exists(root):\n        os.makedirs(root)\n    if not os.path.exists(f\"{root}images/{split}\"):\n        os.makedirs(f\"{root}images/{split}\")\n        os.makedirs(f\"{root}labels/{split}\")\n    \n    for i, key in enumerate(keys):\n        img = np.array(Image.open(f\"{img_folder}{key}\"))\n        Image.fromarray(img).save(f\"{root}images/{split}/im{i}.jpg\")\n        df = annotation_to_df(annotations[key], img.shape)\n        df.to_csv(f\"{root}labels/{split}/im{i}.txt\", header=False, index=False, sep='\\t')","metadata":{"execution":{"iopub.status.busy":"2023-07-18T09:45:08.318539Z","iopub.execute_input":"2023-07-18T09:45:08.319444Z","iopub.status.idle":"2023-07-18T09:45:08.333019Z","shell.execute_reply.started":"2023-07-18T09:45:08.319408Z","shell.execute_reply":"2023-07-18T09:45:08.332143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_keys), len(val_keys)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-18T09:45:08.334422Z","iopub.execute_input":"2023-07-18T09:45:08.335300Z","iopub.status.idle":"2023-07-18T09:45:08.348833Z","shell.execute_reply.started":"2023-07-18T09:45:08.335264Z","shell.execute_reply":"2023-07-18T09:45:08.347914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"add_dataset(train_keys, train_annotations, train_img_folder, \"/kaggle/working/datasets/faceset/\", \"train\")\n","metadata":{"execution":{"iopub.status.busy":"2023-07-18T09:45:08.349871Z","iopub.execute_input":"2023-07-18T09:45:08.350222Z","iopub.status.idle":"2023-07-18T09:48:48.152543Z","shell.execute_reply.started":"2023-07-18T09:45:08.350191Z","shell.execute_reply":"2023-07-18T09:48:48.151403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"add_dataset(val_keys, val_annotations, val_img_folder, \"/kaggle/working/datasets/faceset/\", \"val\")\n","metadata":{"execution":{"iopub.status.busy":"2023-07-18T09:48:48.154462Z","iopub.execute_input":"2023-07-18T09:48:48.154843Z","iopub.status.idle":"2023-07-18T09:49:56.719312Z","shell.execute_reply.started":"2023-07-18T09:48:48.154804Z","shell.execute_reply":"2023-07-18T09:49:56.718344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dict_file = {\"path\":\"/kaggle/working/datasets/faceset\",\n             \"train\":\"images/train\",\n             \"val\":\"images/val\",\n             \"nc\":0,\n             \"names\": [\"face\"]}\n\nwith open(\"/kaggle/working/dataset.yaml\", 'w') as file:\n    documents = yaml.dump(dict_file, file)","metadata":{"execution":{"iopub.status.busy":"2023-07-18T09:49:56.720680Z","iopub.execute_input":"2023-07-18T09:49:56.721138Z","iopub.status.idle":"2023-07-18T09:49:56.734384Z","shell.execute_reply.started":"2023-07-18T09:49:56.721077Z","shell.execute_reply":"2023-07-18T09:49:56.732761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"********************************************************************************************************\n","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/ultralytics/yolov5\n%cd yolov5\n%pip install -r \"requirements.txt","metadata":{"execution":{"iopub.status.busy":"2023-07-18T09:49:56.735933Z","iopub.execute_input":"2023-07-18T09:49:56.736639Z","iopub.status.idle":"2023-07-18T09:50:00.712222Z","shell.execute_reply.started":"2023-07-18T09:49:56.736605Z","shell.execute_reply":"2023-07-18T09:50:00.710923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# training","metadata":{}},{"cell_type":"code","source":"!python train.py --img 640 --epochs 12 --batch-size 32 --data /kaggle/working/dataset.yaml --weights yolov5s.pt\n","metadata":{"execution":{"iopub.status.busy":"2023-07-18T09:50:00.714542Z","iopub.execute_input":"2023-07-18T09:50:00.714935Z","iopub.status.idle":"2023-07-18T12:34:07.648815Z","shell.execute_reply.started":"2023-07-18T09:50:00.714896Z","shell.execute_reply":"2023-07-18T12:34:07.647595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_yolov5 = torch.hub.load('/kaggle/working/yolov5', 'custom', path='runs/train/exp/weights/best.pt', force_reload=True, source='local')","metadata":{"execution":{"iopub.status.busy":"2023-07-18T12:34:07.651231Z","iopub.execute_input":"2023-07-18T12:34:07.651621Z","iopub.status.idle":"2023-07-18T12:34:14.808669Z","shell.execute_reply.started":"2023-07-18T12:34:07.651581Z","shell.execute_reply":"2023-07-18T12:34:14.807739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Changing settings to prevent finding the faces multiple times\ncustom_yolov5.conf = 0.5\ncustom_yolov5.iou = 0.3","metadata":{"execution":{"iopub.status.busy":"2023-07-18T12:34:14.810113Z","iopub.execute_input":"2023-07-18T12:34:14.810695Z","iopub.status.idle":"2023-07-18T12:34:14.815903Z","shell.execute_reply.started":"2023-07-18T12:34:14.810659Z","shell.execute_reply":"2023-07-18T12:34:14.814847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = custom_yolov5(f\"{train_img_folder}{train_keys[5]}\")\noutput.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-18T12:34:14.817341Z","iopub.execute_input":"2023-07-18T12:34:14.817732Z","iopub.status.idle":"2023-07-18T12:34:16.197813Z","shell.execute_reply.started":"2023-07-18T12:34:14.817700Z","shell.execute_reply":"2023-07-18T12:34:16.196748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = custom_yolov5(\"/kaggle/input/face123/image.jpg\")\noutput.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-18T12:34:16.203668Z","iopub.execute_input":"2023-07-18T12:34:16.204061Z","iopub.status.idle":"2023-07-18T12:34:16.882458Z","shell.execute_reply.started":"2023-07-18T12:34:16.204027Z","shell.execute_reply":"2023-07-18T12:34:16.881049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = custom_yolov5(\"/kaggle/input/aaaaa-and/12121.jpg\")\noutput.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-18T12:34:16.883939Z","iopub.execute_input":"2023-07-18T12:34:16.884611Z","iopub.status.idle":"2023-07-18T12:34:18.181797Z","shell.execute_reply.started":"2023-07-18T12:34:16.884572Z","shell.execute_reply":"2023-07-18T12:34:18.180221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"********************************************************************************************************","metadata":{}},{"cell_type":"markdown","source":"********************************************************************************************************","metadata":{}}]}